{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "#nltk.download('punkt_tab')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('averaged_perceptron_tagger_eng')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk import ngrams\n",
    "from nltk import pos_tag\n",
    "from nltk import FreqDist\n",
    "from nltk.chunk import RegexpParser\n",
    "from nltk.stem import *\n",
    "import string\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200\n",
      "400\n",
      "400\n",
      "{'3': 400, '10': 400, '9': 400, '1': 400, '2': 400, '7': 400, '4': 400, '8': 400}\n",
      "{'4': 50, '7': 50, '3': 50, '10': 50, '9': 50, '2': 50, '8': 50, '1': 50}\n",
      "{'3': 50, '9': 50, '4': 50, '2': 50, '8': 50, '1': 50, '10': 50, '7': 50}\n"
     ]
    }
   ],
   "source": [
    "# path for input text files\n",
    "data_path = \"data\\\\data\\\\\"\n",
    "\n",
    "# separate into positive and negative\n",
    "neg_list = os.listdir(data_path + \"neg\")\n",
    "pos_list = os.listdir(data_path + \"pos\")\n",
    "\n",
    "all_reviews = neg_list + pos_list\n",
    "\n",
    "\n",
    "def get_target_values(data_set):\n",
    "    output_id = []\n",
    "    output_rating = []\n",
    "    for doc_id in data_set:\n",
    "        rating = doc_id.split('_')[1].split('.')[0]\n",
    "        output_id.append(doc_id)\n",
    "        output_rating.append(rating)\n",
    "    return output_id, output_rating\n",
    "\n",
    "all_doc_id, all_doc_rating = get_target_values(all_reviews)  # Retrieve all document ID's and associated ratings in 2 lists\n",
    "\n",
    "train_id, X_temp, train_ratings, y_temp = train_test_split(all_doc_id, all_doc_rating, test_size=0.2, random_state=42, stratify=all_doc_rating) # Split to training and temp\n",
    "\n",
    "dev_id, test_id, dev_ratings, test_ratings = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp) # Split temp into dev and test\n",
    "\n",
    "def populate_set(data_set, data_set_rating, data_path):\n",
    "    output_set = {}\n",
    "    for rating_id, id in enumerate(data_set):\n",
    "        if int(data_set_rating[rating_id]) < 5:\n",
    "            with open(data_path + \"neg\\\\\" + id, \"r\", encoding=\"utf8\") as f:\n",
    "                output_set[id] = f.read()\n",
    "        else:\n",
    "            with open(data_path + \"pos\\\\\" + id, \"r\", encoding=\"utf8\") as f:\n",
    "                output_set[id] = f.read()\n",
    "    return output_set\n",
    "\n",
    "data_path = \"data\\\\data\\\\\"\n",
    "training_set = {}  # 80% 3200\n",
    "dev_set = {}  # 10% 400\n",
    "test_set = {}  # 10% 400\n",
    "\n",
    "# Populate data sets\n",
    "training_set = populate_set(train_id, train_ratings, data_path)\n",
    "dev_set = populate_set(dev_id, dev_ratings, data_path)\n",
    "test_set = populate_set(test_id, test_ratings, data_path)\n",
    "print(len(training_set))\n",
    "print(len(dev_set))\n",
    "print(len(test_set))\n",
    "train_rating_dict = {}\n",
    "dev_rating_dict = {}\n",
    "test_rating_dict = {}\n",
    "for rating in train_ratings:\n",
    "    if rating in train_rating_dict.keys():\n",
    "        train_rating_dict[rating] += 1\n",
    "    else:\n",
    "        train_rating_dict[rating] = 1\n",
    "for rating in dev_ratings:\n",
    "    if rating in dev_rating_dict.keys():\n",
    "        dev_rating_dict[rating] += 1\n",
    "    else:\n",
    "        dev_rating_dict[rating] = 1\n",
    "for rating in test_ratings:\n",
    "    if rating in test_rating_dict.keys():\n",
    "        test_rating_dict[rating] += 1\n",
    "    else:\n",
    "        test_rating_dict[rating] = 1\n",
    "print(train_rating_dict)\n",
    "print(dev_rating_dict)\n",
    "print(test_rating_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_tokenize(data_set, stemming, lemmatization, ngram_cond):\n",
    "    output = {}\n",
    "    stopword_list = set(stopwords.words('english'))\n",
    "    st = PorterStemmer()\n",
    "    lem = WordNetLemmatizer()\n",
    "    grammar_NP = \"NP: {<DT>?<JJ>*<NN>+}\"\n",
    "    chunker = RegexpParser(grammar_NP)\n",
    "\n",
    "    for doc_id, text in data_set.items():\n",
    "\n",
    "        tokens = [word.lower() for word in word_tokenize(text)]  # Tokenize text and set to lowercase\n",
    "\n",
    "\n",
    "        pos_tags = pos_tag(tokens)  # Generate POS tags\n",
    "        \n",
    "        tree = chunker.parse(pos_tags)  # Use chunking to gather noun phrases\n",
    "        NP = []  # Noun Phrases\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == \"NP\":\n",
    "                NP.append(\" \".join(word for word, tag in subtree.leaves()))\n",
    "\n",
    "        if stemming == True:\n",
    "            tokens_edited = [st.stem(word) for word in tokens]\n",
    "            NP_edited = [st.stem(phrase) for phrase in NP]\n",
    "        elif lemmatization == True:\n",
    "            tokens_edited = [lem.lemmatize(word) for word in tokens]\n",
    "            NP_edited = [lem.lemmatize(phrase) for phrase in NP]\n",
    "        else:\n",
    "            tokens_edited = tokens\n",
    "            NP_edited = NP\n",
    "\n",
    "        ngram = []\n",
    "        \n",
    "        if ngram_cond == 2:\n",
    "            ngram = ['_'.join(gram) for gram in ngrams(tokens, 2)]  # generate bigrams using ngrams function\n",
    "        if ngram_cond == 3:\n",
    "            ngram = ['_'.join(gram) for gram in ngrams(tokens, 3)]  # generate trigrams using ngrams function\n",
    "\n",
    "        # NEED TO EDIT THIS TO MAKE SURE IT REMOVES STOPWORDS FROM BIGRAMS AND TRIGRAMS\n",
    "        tokens_edited = [word for word in tokens_edited if word not in stopword_list and word not in string.punctuation and word not in [\"br\", '``', \"n't\", \"''\", \"...\", \"'s\", \"'re\"]]  # Remove stopword, punctuation and misc.\n",
    "        NP_edited = [word for word in NP_edited if word not in stopword_list and word not in string.punctuation and word not in [\"br\", '``', \"n't\", \"''\", \"...\", \"'s\", \"'re\"]]\n",
    "\n",
    "        if ngram_cond == 2 or ngram_cond == 3:\n",
    "            combined_tokens = list(set(tokens_edited + NP_edited + ngram))  # Combine all to get an output\n",
    "        else:\n",
    "            combined_tokens = list(set(tokens_edited + NP_edited))\n",
    "        \n",
    "        output[doc_id] = combined_tokens\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_vocabulary(training_set):\n",
    "    all_terms = []\n",
    "    for key, text in training_set.items():\n",
    "        for word in text:\n",
    "            all_terms.append(word)\n",
    "    return list(set(all_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_doc_term_count(all_terms, doc_term_freqs):  # Returns a dictionary of terms with counts of how many documents the term appears in\n",
    "    count_term_appears_in_unique_doc = {}\n",
    "    for doc_id in doc_term_freqs.keys():\n",
    "        for term in all_terms:\n",
    "            if term in doc_term_freqs[doc_id].keys():\n",
    "                if term in count_term_appears_in_unique_doc.keys():\n",
    "                    count_term_appears_in_unique_doc[term] = count_term_appears_in_unique_doc[term] + 1\n",
    "                else:\n",
    "                    count_term_appears_in_unique_doc[term] = 1\n",
    "    return count_term_appears_in_unique_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_terms(training_set):\n",
    "    doc_term_freqs = {}\n",
    "    for doc_id in training_set.keys():\n",
    "        term_freqs = {}\n",
    "        for word in training_set[doc_id]:\n",
    "            if word in term_freqs:\n",
    "                term_freqs[word] += 1\n",
    "            else:\n",
    "                term_freqs[word] = 1\n",
    "        # Sublinear TF scaling as a secondary form of normalisation\n",
    "        for word in term_freqs.keys():\n",
    "            term_freqs[word] = 1 + math.log(term_freqs[word], 10)\n",
    "        # Normalise by document length\n",
    "        doc_length = len(training_set[doc_id])\n",
    "        for word in term_freqs.keys():\n",
    "            term_freqs[word] /= doc_length\n",
    "        # Add sublinear scaled normalised TF to output dictionary\n",
    "        doc_term_freqs[doc_id] = term_freqs\n",
    "    return doc_term_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_idfs(data_set, all_terms, doc_term_count):\n",
    "    term_idfs = {}\n",
    "    for term in all_terms:\n",
    "        term_doc_count = doc_term_count.get(term)  # no. of documents containing the term\n",
    "        if term_doc_count != None:\n",
    "            term_idfs[term] = math.log(1 + (len(data_set)/float(1 + term_doc_count)), 10)\n",
    "    return term_idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf_dict(data_set, doc_term_freqs, term_idfs):\n",
    "    all_doc_tf_idf = {}\n",
    "    for doc_id, tokens in data_set.items():\n",
    "        doc_tf_idf = {}\n",
    "        for token, idf in term_idfs.items():\n",
    "            if token in tokens:\n",
    "                doc_tf_idf[token] = doc_term_freqs[doc_id][token] * idf\n",
    "            else:\n",
    "                doc_tf_idf[token] = 0.0\n",
    "        all_doc_tf_idf[doc_id] = doc_tf_idf\n",
    "    return all_doc_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_tfidf(norm_all_doc_tfidf):\n",
    "    output = []\n",
    "    for doc_id in norm_all_doc_tfidf.keys():\n",
    "        document_vector = []\n",
    "        for term in norm_all_doc_tfidf[doc_id].keys():\n",
    "            document_vector.append(float(norm_all_doc_tfidf[doc_id][term]))\n",
    "        output.append(document_vector)\n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_values(data_set):\n",
    "    output = []\n",
    "    for doc_id in data_set.keys():\n",
    "        rating = doc_id.split('_')[1].split('.')[0]\n",
    "        if int(rating) >= 7:\n",
    "            output.append(\"P\")\n",
    "        else:\n",
    "            output.append(\"N\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_tfidf(all_doc_tfidf):\n",
    "    for doc_id in all_doc_tfidf.keys():\n",
    "        max_idf = 0.0\n",
    "        for term in all_doc_tfidf[doc_id].keys():\n",
    "            idf_value = all_doc_tfidf[doc_id][term]\n",
    "            if float(idf_value) > max_idf:\n",
    "                max_idf = idf_value\n",
    "        for term in all_doc_tfidf[doc_id].keys():\n",
    "            all_doc_tfidf[doc_id][term] = all_doc_tfidf[doc_id][term] / max_idf  # Normalise TFIDF values so they are between 0 and 1\n",
    "    return all_doc_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_norm(data_set, doc_term_freq, doc_term_count):\n",
    "    normalised_documents = []\n",
    "    for doc_id in data_set.keys():\n",
    "        for term in doc_term_count.keys():\n",
    "            document = []\n",
    "            if term in doc_term_freq[doc_id].keys():\n",
    "                document.append(doc_term_freq[doc_id][term])\n",
    "            else:\n",
    "                document.append(0)\n",
    "        document = np.linalg.norm(document, keepdims=True)\n",
    "        normalised_documents.append(document)\n",
    "    return normalised_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = nltk_tokenize(training_set, stemming=False, lemmatization=False, ngram_cond = 2)  # Tokenize, lemmatize and stem documents => Dict[Doc_ID] : Tokens\n",
    "dev_set = nltk_tokenize(dev_set, stemming=False, lemmatization=False, ngram_cond=2)\n",
    "#test_set = nltk_tokenize(test_set, stemming=False, lemmatization=False)\n",
    "\n",
    "all_terms = collect_vocabulary(training_set)  # Retrieve list of all terms => all_terms (unique)\n",
    "\n",
    "doc_term_freq = count_terms(training_set)  # Retrieve term frequency values for each term in each document => Dict[Doc_ID] : Dict[Token] : TF\n",
    "dev_dtf = count_terms(dev_set)  # Retrieve TF for each term in each document for dev set\n",
    "#test_dtf = count_terms(test_set)\n",
    "\n",
    "# Need to get IDF values for each word in corpus = total no docs in corpus/no docs containing word\n",
    "\n",
    "doc_term_count = collect_doc_term_count(all_terms, doc_term_freq)  # Returns a dictionary of each term in the corpus and how many documents it appears in => Dict[term] : CorpusFreq\n",
    "\n",
    "doc_term_count = {word: count for word, count in doc_term_count.items() if 80 <= count <= 1800}\n",
    "\n",
    "\n",
    "#term_l2_norm = l2_norm(training_set, doc_term_freq, doc_term_count)\n",
    "\n",
    "#print(term_l2_norm[0])\n",
    "\n",
    "term_idfs = calculate_idfs(training_set, all_terms, doc_term_count)  # Returns a dictionary of each term in the corpus => Dict[term] : IDF\n",
    "\n",
    "# Need a function that takes in a data set (training/dev/test) and returns a dictionary of tfidf values => Dict[doc_id] : Dict[Term] : TFIDF\n",
    "\n",
    "all_doc_tfidf = get_tf_idf_dict(training_set, doc_term_freq, term_idfs)  # Returns a dictionary of tfidf values for all documents in data set => Dict[doc_id] : Dict[Term] : TFIDF\n",
    "dev_tfidf = get_tf_idf_dict(dev_set, dev_dtf, term_idfs)\n",
    "#test_tfidf = get_tf_idf_dict(test_set, test_dtf, term_idfs)\n",
    "# Need a function to normalise each documents tfidf scores so that it is between 0 and 1 to account for document length\n",
    "\n",
    "norm_all_doc_tfidf = normalise_tfidf(all_doc_tfidf)  # Returns normalised tfidf values for all training documents by dividing all tfidf scores in each document by the maximum tfidf value of that document\n",
    "                                                     # Dict[doc_id] : Dict[Term] : TFIDF (normalised)\n",
    "\n",
    "norm_dev_tfidf = normalise_tfidf(dev_tfidf)\n",
    "#norm_test_tfidf = normalise_tfidf(test_tfidf)\n",
    "\n",
    "# Need a function to vectorize all_doc_tfidf so that it can be passed into NB classifier\n",
    "\n",
    "train_vec_tfidf = vectorize_tfidf(norm_all_doc_tfidf)\n",
    "dev_vec_tfidf = vectorize_tfidf(norm_dev_tfidf)\n",
    "#test_vec_tfidf = vectorize_tfidf(norm_test_tfidf)\n",
    "\n",
    "# Need a function to get the target values in a vector\n",
    "\n",
    "training_target_values = get_target_values(training_set)  # Training vector\n",
    "dev_target_values = get_target_values(dev_set)  # Development vector\n",
    "#test_target_values = get_target_values(test_set)  # Test vector\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Visualisation of training term frequency in unique documents indicating significance of each term: Common terms and very low frequency terms are are less significant.\n",
    "import matplotlib.pyplot as plt\n",
    "term_freqs = [count for word, count in sorted(doc_term_count.items(), key=lambda item: item[1])]\n",
    "x_axis = np.arange(0, len(term_freqs), 1)\n",
    "plt.plot(x_axis, term_freqs)\n",
    "plt.show()\n",
    "for index, freq in enumerate(term_freqs):\n",
    "    if freq == 16:\n",
    "        print(index)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3200, 1610)\n",
      "(400, 1610)\n",
      "0.01 0.8175\n",
      "0.02 0.8175\n",
      "0.03 0.8175\n",
      "0.04 0.8175\n",
      "0.05 0.8175\n",
      "0.060000000000000005 0.8175\n",
      "0.06999999999999999 0.8175\n",
      "0.08 0.8175\n",
      "0.09 0.8175\n",
      "0.09999999999999999 0.8175\n",
      "0.11 0.8175\n",
      "0.12 0.8175\n",
      "0.13 0.8175\n",
      "0.14 0.8175\n",
      "0.15000000000000002 0.8175\n",
      "0.16 0.8175\n",
      "0.17 0.8175\n",
      "0.18000000000000002 0.8175\n",
      "0.19 0.8175\n",
      "0.2 0.8175\n",
      "0.21000000000000002 0.8175\n",
      "0.22 0.8175\n",
      "0.23 0.8175\n",
      "0.24000000000000002 0.8175\n",
      "0.25 0.8175\n",
      "0.26 0.8175\n",
      "0.27 0.8175\n",
      "0.28 0.8175\n",
      "0.29000000000000004 0.8175\n",
      "0.3 0.8175\n",
      "0.31 0.8175\n",
      "0.32 0.8175\n",
      "0.33 0.8175\n",
      "0.34 0.8175\n",
      "0.35000000000000003 0.8175\n",
      "0.36000000000000004 0.8175\n",
      "0.37 0.8175\n",
      "0.38 0.8175\n",
      "0.39 0.8175\n",
      "0.4 0.8175\n",
      "0.41000000000000003 0.8175\n",
      "0.42000000000000004 0.8175\n",
      "0.43 0.8175\n",
      "0.44 0.8175\n",
      "0.45 0.8175\n",
      "0.46 0.8175\n",
      "0.47000000000000003 0.8175\n",
      "0.48000000000000004 0.8175\n",
      "0.49 0.8175\n",
      "0.5 0.8175\n",
      "0.51 0.8175\n",
      "0.52 0.8175\n",
      "0.53 0.8175\n",
      "0.54 0.8175\n",
      "0.55 0.8175\n",
      "0.56 0.8175\n",
      "0.5700000000000001 0.8175\n",
      "0.5800000000000001 0.8175\n",
      "0.59 0.815\n",
      "0.6 0.815\n",
      "0.61 0.815\n",
      "0.62 0.815\n",
      "0.63 0.815\n",
      "0.64 0.815\n",
      "0.65 0.815\n",
      "0.66 0.815\n",
      "0.67 0.815\n",
      "0.68 0.815\n",
      "0.6900000000000001 0.815\n",
      "0.7000000000000001 0.815\n",
      "0.7100000000000001 0.815\n",
      "0.72 0.815\n",
      "0.73 0.815\n",
      "0.74 0.815\n",
      "0.75 0.815\n",
      "0.76 0.815\n",
      "0.77 0.815\n",
      "0.78 0.815\n",
      "0.79 0.815\n",
      "0.8 0.815\n",
      "0.81 0.815\n",
      "0.8200000000000001 0.815\n",
      "0.8300000000000001 0.815\n",
      "0.8400000000000001 0.815\n",
      "0.85 0.815\n",
      "0.86 0.815\n",
      "0.87 0.815\n",
      "0.88 0.815\n",
      "0.89 0.815\n",
      "0.9 0.815\n",
      "0.91 0.815\n",
      "0.92 0.815\n",
      "0.93 0.815\n",
      "0.9400000000000001 0.815\n",
      "0.9500000000000001 0.815\n",
      "0.9600000000000001 0.815\n",
      "0.97 0.815\n",
      "0.98 0.815\n",
      "0.99 0.815\n",
      "1.0 0.815\n"
     ]
    }
   ],
   "source": [
    "X = train_vec_tfidf\n",
    "Y = dev_vec_tfidf\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "for i in np.arange(0.01, 1.01, 0.01):\n",
    "    clf = MultinomialNB(alpha=i)\n",
    "    clf.fit(X, training_target_values)\n",
    "    print(i, clf.score(Y, dev_target_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815\n"
     ]
    }
   ],
   "source": [
    "## Insert code here for manual NB classifier\n",
    "class NBClassifier:\n",
    "    def __init__(self, alpha, feature_count):\n",
    "        self.alpha = alpha\n",
    "        self.log_class_conditional_likelihoods = 0\n",
    "        self.log_class_priors = 0\n",
    "        self.feature_count = feature_count\n",
    "\n",
    "\n",
    "    def estimate_log_class_priors(self):\n",
    "        \"\"\"\n",
    "        Given a data set with binary response variable (0s and 1s) in the\n",
    "        left-most column, calculate the logarithm of the empirical class priors,\n",
    "        that is, the logarithm of the proportions of 0s and 1s:\n",
    "            log(p(C=0)) and log(p(C=1))\n",
    "\n",
    "        :param data: a two-dimensional numpy-array with shape = [n_samples, 1 + n_features]\n",
    "                    the first column contains the binary response (coded as 0s and 1s).\n",
    "\n",
    "        :return log_class_priors: a numpy array of length two\n",
    "\n",
    "        OLD CODE REMOVE LATER IF NOT NEEDED\n",
    "        probN = 0\n",
    "        probP = 0\n",
    "        for row in data:\n",
    "            if row[0] == 1:\n",
    "                probN = probN + 1\n",
    "            else:\n",
    "                probP = probP + 1\n",
    "        probN = np.log(probN/len(data))\n",
    "        probP = np.log(probP/len(data))\n",
    "        log_class_priors = np.array((probP, probN))\n",
    "        \"\"\"\n",
    "        #  Log class priors should be equal as training data is equally distributed between positive and negative reviews\n",
    "        log_class_priors = np.array((np.log(0.5), np.log(0.5)))\n",
    "        return log_class_priors\n",
    "    \n",
    "    def get_class_values(self, tfidf_vec, target_values): #tfidf_vec = dev_vec_tfidf example\n",
    "        total_tfidfs_pos = 0\n",
    "        total_tfidfs_neg = 0\n",
    "        tfidfs_pos = np.zeros_like(tfidf_vec[0])\n",
    "        tfidfs_neg = np.zeros_like(tfidf_vec[0])\n",
    "        for i in range(len(tfidf_vec)):\n",
    "            sentiment = target_values[i]\n",
    "            if sentiment == \"P\":\n",
    "                total_tfidfs_pos += np.sum(tfidf_vec[i])\n",
    "                tfidfs_pos += tfidf_vec[i]\n",
    "            else:\n",
    "                total_tfidfs_neg += np.sum(tfidf_vec[i])\n",
    "                tfidfs_neg += tfidf_vec[i]\n",
    "        return total_tfidfs_pos, total_tfidfs_neg, tfidfs_pos, tfidfs_neg\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    def estimate_log_class_conditional_likelihoods(self, total_tfidfs_pos, total_tfidfs_neg, tfidfs_pos, tfidfs_neg):\n",
    "        \"\"\"\n",
    "        Given a data set with binary response variable (0s and 1s) in the\n",
    "        left-most column and binary features (words), calculate the empirical\n",
    "        class-conditional likelihoods, that is,\n",
    "        log(P(w_i | c)) for all features w_i and both classes (c in {0, 1}).\n",
    "\n",
    "        Assume a multinomial feature distribution and use Laplace smoothing\n",
    "        if alpha > 0.\n",
    "\n",
    "        :param data: a two-dimensional numpy-array with shape = [n_samples, 1 + n_features]\n",
    "\n",
    "        :return theta:\n",
    "            a numpy array of shape = [2, n_features]. theta[j, i] corresponds to the\n",
    "            logarithm of the probability of feature i appearing in a sample belonging \n",
    "            to class j.\n",
    "        \"\"\"\n",
    "        alpha = self.alpha\n",
    "        PPOS = np.log((tfidfs_pos + alpha)/(total_tfidfs_pos + alpha * len(tfidfs_pos)))\n",
    "        PNEG = np.log((tfidfs_neg + alpha)/(total_tfidfs_neg + alpha * len(tfidfs_neg)))\n",
    "        theta = np.array((PPOS, PNEG))\n",
    "\n",
    "        return theta\n",
    "\n",
    "    def predict(self, new_data):\n",
    "        class_predictions = np.empty(len(new_data), dtype=str)\n",
    "        for document, terms in enumerate(new_data):\n",
    "            PosRating = self.log_class_priors[0] + np.sum(terms * self.log_class_conditional_likelihoods[0])\n",
    "            NegRating = self. log_class_priors[1] + np.sum(terms * self.log_class_conditional_likelihoods[1])\n",
    "            if PosRating > NegRating:\n",
    "                class_predictions[document] = \"P\"\n",
    "            else:\n",
    "                class_predictions[document] = \"N\"\n",
    "        return class_predictions\n",
    "    \n",
    "    def train(self, tfidf_vec, target_values):\n",
    "        self.log_class_priors = self.estimate_log_class_priors()\n",
    "        total_tfidfs_pos, total_tfidfs_neg, tfidfs_pos, tfidfs_neg = self.get_class_values(tfidf_vec, target_values)\n",
    "        self.log_class_conditional_likelihoods = self.estimate_log_class_conditional_likelihoods(total_tfidfs_pos, total_tfidfs_neg, tfidfs_pos, tfidfs_neg)\n",
    "\n",
    "def create_classifier(features, tfidf_vec, target_values):\n",
    "    classifier = NBClassifier(alpha=0.8, feature_count=features)\n",
    "    classifier.train(tfidf_vec, target_values)\n",
    "    return classifier\n",
    "\n",
    "feature_count = X.shape[1]\n",
    "classifier = create_classifier(feature_count, train_vec_tfidf, training_target_values)\n",
    "predictions = classifier.predict(dev_vec_tfidf)\n",
    "correct_count = 0\n",
    "for index, pred in enumerate(predictions):\n",
    "    if pred == dev_target_values[index]:\n",
    "        correct_count += 1\n",
    "print(correct_count/400)\n",
    "#52"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
